{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1044630\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.63s) \n",
      "Downloaded feature group: city_weather (version 1)\n",
      "      city_id  temp  wind_speed           description  precip  humidity  \\\n",
      "0  C-731988ba    52           1  Patchy rain possible     0.0        80   \n",
      "1  C-841ebdcb    66           6         Partly cloudy     0.0        84   \n",
      "2  C-ef47bdcd    10           6                 Sunny     0.0        57   \n",
      "3  C-ff8c0c3c    34           8              Overcast     0.0       100   \n",
      "4  C-3dbd8b2e    41          11         Partly cloudy     0.0        73   \n",
      "\n",
      "   visibility  pressure     id                       event_time  \\\n",
      "0           6      1015   8790 2024-10-10 20:13:27.088206+00:00   \n",
      "1           6      1020  52029 2024-10-10 20:13:27.088206+00:00   \n",
      "2           6      1036  13063 2024-10-10 20:13:27.088206+00:00   \n",
      "3           6      1024  16910 2024-10-10 20:13:27.088206+00:00   \n",
      "4           6      1021  18928 2024-10-10 20:13:27.088206+00:00   \n",
      "\n",
      "                   datetime  \n",
      "0 2019-02-14 05:00:00+00:00  \n",
      "1 2019-01-07 20:00:00+00:00  \n",
      "2 2019-02-08 06:00:00+00:00  \n",
      "3 2019-01-15 13:00:00+00:00  \n",
      "4 2019-01-07 15:00:00+00:00  \n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.55s) \n",
      "Downloaded feature group: drivers_table (version 1)\n",
      "    driver_id               name  gender  age  experience driving_style  \\\n",
      "0  7fd8f066-0        John Graham    male   37           3  conservative   \n",
      "1  dfb33269-1    William Hoffman    male   52          28  conservative   \n",
      "2  6a2bd8a7-6          Molly Lee  female   50          17     proactive   \n",
      "3  ddcaf636-8  Christopher Rubio    male   57           9     proactive   \n",
      "4  0fa8f219-7          John Wade    male   42           9     proactive   \n",
      "\n",
      "   ratings  vehicle_no  average_speed_mph    id  \\\n",
      "0        8    33677790              49.30   495   \n",
      "1        7    20516509              37.67   590   \n",
      "2        6    12141617              61.89  1117   \n",
      "3        8    31057269              59.95   310   \n",
      "4        4    17787739              59.60   347   \n",
      "\n",
      "                        event_time  \n",
      "0 2024-10-10 20:13:27.092204+00:00  \n",
      "1 2024-10-10 20:13:27.092204+00:00  \n",
      "2 2024-10-10 20:13:27.092204+00:00  \n",
      "3 2024-10-10 20:13:27.092204+00:00  \n",
      "4 2024-10-10 20:13:27.092204+00:00  \n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.65s) \n",
      "Downloaded feature group: routes_table (version 1)\n",
      "     route_id   origin_id destination_id  distance  average_hours   id  \\\n",
      "0  R-02124ef5  C-c4565ee8     C-3dbd8b2e   2018.08          40.36  641   \n",
      "1  R-7ee42348  C-ff8c0c3c     C-927ceb5e    239.93           4.80  721   \n",
      "2  R-038f3a7c  C-b6e04c88     C-ef47bdcd    776.33          15.53  924   \n",
      "3  R-f39a3b9b  C-639c5e36     C-2aaf0e1a   1750.04          35.00  420   \n",
      "4  R-22c767b0  C-3dbd8b2e     C-a9f2c329   1609.60          32.19  826   \n",
      "\n",
      "                        event_time  \n",
      "0 2024-10-10 20:13:27.094205+00:00  \n",
      "1 2024-10-10 20:13:27.094205+00:00  \n",
      "2 2024-10-10 20:13:27.094205+00:00  \n",
      "3 2024-10-10 20:13:27.094205+00:00  \n",
      "4 2024-10-10 20:13:27.094205+00:00  \n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (4.40s) \n",
      "Downloaded feature group: routes_weather (version 1)\n",
      "     route_id                      date  temp  wind_speed  \\\n",
      "0  R-566db3fc 2019-01-21 12:00:00+00:00    28          16   \n",
      "1  R-05a6b7e1 2019-02-13 18:00:00+00:00    16           4   \n",
      "2  R-79047854 2019-01-31 00:00:00+00:00    55           7   \n",
      "3  R-e0263659 2019-01-22 00:00:00+00:00    75           4   \n",
      "4  R-dcbddbb7 2019-02-01 12:00:00+00:00    61           3   \n",
      "\n",
      "                      description  precip  humidity  visibility  pressure  \\\n",
      "0  Moderate or heavy snow showers     0.0        73           4      1015   \n",
      "1                           Clear     0.0        63           6      1021   \n",
      "2                           Sunny     0.0        57           6      1022   \n",
      "3                          Cloudy     0.0        66           6      1016   \n",
      "4                           Clear     0.0        89           6      1011   \n",
      "\n",
      "       id                       event_time  \n",
      "0  245303 2024-10-10 20:13:27.063199+00:00  \n",
      "1  397270 2024-10-10 20:13:27.063199+00:00  \n",
      "2   98159 2024-10-10 20:13:27.063199+00:00  \n",
      "3   30437 2024-10-10 20:13:27.063199+00:00  \n",
      "4  259995 2024-10-10 20:13:27.063199+00:00  \n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (14.53s) \n",
      "Downloaded feature group: traffic_table (version 1)\n",
      "     route_id  no_of_vehicles  accident       id  \\\n",
      "0  R-0f705429          2343.0         0    15237   \n",
      "1  R-f8a25f87           552.0         0   350444   \n",
      "2  R-3b99b000           645.0         0  1673486   \n",
      "3  R-ac453ce8           621.0         0   711241   \n",
      "4  R-af1d28da          2916.0         0  2185148   \n",
      "\n",
      "                        event_time                  datetime  \n",
      "0 2024-10-10 20:13:27.117189+00:00 2019-02-06 20:00:00+00:00  \n",
      "1 2024-10-10 20:13:27.117189+00:00 2019-01-20 19:00:00+00:00  \n",
      "2 2024-10-10 20:13:27.117189+00:00 2019-01-31 04:00:00+00:00  \n",
      "3 2024-10-10 20:13:27.117189+00:00 2019-01-12 00:00:00+00:00  \n",
      "4 2024-10-10 20:13:27.117189+00:00 2019-01-06 10:00:00+00:00  \n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.62s) \n",
      "Downloaded feature group: truck_schedule_table (version 1)\n",
      "   truck_id    route_id            departure_date         estimated_arrival  \\\n",
      "0  23244180  R-b1e8e9c8 2019-02-06 07:00:00+00:00 2019-02-07 04:09:00+00:00   \n",
      "1  10234289  R-d053f5bc 2019-01-22 07:00:00+00:00 2019-01-22 22:51:00+00:00   \n",
      "2  26739096  R-bf6ee666 2019-01-07 07:00:00+00:00 2019-01-07 15:54:36+00:00   \n",
      "3  20067958  R-abc9e78b 2019-01-04 07:00:00+00:00 2019-01-05 05:28:12+00:00   \n",
      "4  23639934  R-7dac228a 2019-01-31 07:00:00+00:00 2019-01-31 13:40:12+00:00   \n",
      "\n",
      "   delay    id                       event_time  \n",
      "0      1  7633 2024-10-10 20:13:27.142196+00:00  \n",
      "1      0  4651 2024-10-10 20:13:27.142196+00:00  \n",
      "2      1  1303 2024-10-10 20:13:27.142196+00:00  \n",
      "3      0   916 2024-10-10 20:13:27.142196+00:00  \n",
      "4      0  6671 2024-10-10 20:13:27.142196+00:00  \n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.52s) \n",
      "Downloaded feature group: trucks_table (version 1)\n",
      "   truck_id  truck_age  load_capacity_pounds  mileage_mpg fuel_type    id  \\\n",
      "0  19336784         11                3000.0           26    diesel  1026   \n",
      "1  35580954         10                6000.0           16    diesel   534   \n",
      "2  19945346          9               15000.0           23    diesel   764   \n",
      "3  31219400          8               15000.0           22    diesel  1272   \n",
      "4  18950712          7               15000.0           22       gas   894   \n",
      "\n",
      "                        event_time  \n",
      "0 2024-10-10 20:13:27.085189+00:00  \n",
      "1 2024-10-10 20:13:27.085189+00:00  \n",
      "2 2024-10-10 20:13:27.085189+00:00  \n",
      "3 2024-10-10 20:13:27.085189+00:00  \n",
      "4 2024-10-10 20:13:27.085189+00:00  \n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "from hsfs.client.exceptions import RestAPIError\n",
    "\n",
    "# Establish connection to Hopsworks\n",
    "project = hopsworks.login(\n",
    "    api_key_value=\"dYTVrTVvbj6Qw82i.YGKHdS9snQYFgOADJIvLdvZ2n2S5BxIAOtvPUEmAyd56bvaG6xhhGyNM3nYbexaP\"\n",
    ")\n",
    "\n",
    "# Access the Feature Store\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "# List of feature groups and their versions\n",
    "feature_groups = [\n",
    "    {\"name\": \"city_weather\", \"version\": 1},\n",
    "    {\"name\": \"drivers_table\", \"version\": 1},\n",
    "    {\"name\": \"routes_table\", \"version\": 1},\n",
    "    {\"name\": \"routes_weather\", \"version\": 1},\n",
    "    {\"name\": \"traffic_table\", \"version\": 1},  # Corrected typo\n",
    "    {\"name\": \"truck_schedule_table\", \"version\": 1},\n",
    "    {\"name\": \"trucks_table\", \"version\": 1},\n",
    "]\n",
    "# Initialize an empty dictionary to hold DataFrames for each feature group\n",
    "feature_group_data = {}\n",
    "\n",
    "# Loop over the list of feature groups and download them\n",
    "for fg in feature_groups:\n",
    "    try:\n",
    "        # Retrieve the feature group by its name and version\n",
    "        feature_group = fs.get_feature_group(fg['name'], version=fg['version'])\n",
    "        df = feature_group.read()  # Read the feature group as a DataFrame\n",
    "        \n",
    "        # Save the DataFrame in the dictionary with the feature group's name as the key\n",
    "        feature_group_data[fg['name']] = df\n",
    "\n",
    "        print(f\"Downloaded feature group: {fg['name']} (version {fg['version']})\")\n",
    "        print(df.head())  # Optionally display the first few rows of the DataFrame\n",
    "\n",
    "    except RestAPIError as e:\n",
    "        print(f\"Error downloading feature group: {fg['name']} (version {fg['version']})\")\n",
    "        print(e)\n",
    "\n",
    "# After the loop, you will have each feature group stored in the `feature_group_data` dictionary\n",
    "# Access each DataFrame like this: feature_group_data['city_weather'], etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['city_weather', 'drivers_table', 'routes_table', 'routes_weather', 'traffic_table', 'truck_schedule_table', 'trucks_table'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_group_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_id</th>\n",
       "      <th>temp</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>description</th>\n",
       "      <th>precip</th>\n",
       "      <th>humidity</th>\n",
       "      <th>visibility</th>\n",
       "      <th>pressure</th>\n",
       "      <th>id</th>\n",
       "      <th>event_time</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C-731988ba</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>Patchy rain possible</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>1015</td>\n",
       "      <td>8790</td>\n",
       "      <td>2024-10-10 20:13:27.088206+00:00</td>\n",
       "      <td>2019-02-14 05:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C-841ebdcb</td>\n",
       "      <td>66</td>\n",
       "      <td>6</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84</td>\n",
       "      <td>6</td>\n",
       "      <td>1020</td>\n",
       "      <td>52029</td>\n",
       "      <td>2024-10-10 20:13:27.088206+00:00</td>\n",
       "      <td>2019-01-07 20:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C-ef47bdcd</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "      <td>6</td>\n",
       "      <td>1036</td>\n",
       "      <td>13063</td>\n",
       "      <td>2024-10-10 20:13:27.088206+00:00</td>\n",
       "      <td>2019-02-08 06:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C-ff8c0c3c</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>1024</td>\n",
       "      <td>16910</td>\n",
       "      <td>2024-10-10 20:13:27.088206+00:00</td>\n",
       "      <td>2019-01-15 13:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C-3dbd8b2e</td>\n",
       "      <td>41</td>\n",
       "      <td>11</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "      <td>1021</td>\n",
       "      <td>18928</td>\n",
       "      <td>2024-10-10 20:13:27.088206+00:00</td>\n",
       "      <td>2019-01-07 15:00:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      city_id  temp  wind_speed           description  precip  humidity  \\\n",
       "0  C-731988ba    52           1  Patchy rain possible     0.0        80   \n",
       "1  C-841ebdcb    66           6         Partly cloudy     0.0        84   \n",
       "2  C-ef47bdcd    10           6                 Sunny     0.0        57   \n",
       "3  C-ff8c0c3c    34           8              Overcast     0.0       100   \n",
       "4  C-3dbd8b2e    41          11         Partly cloudy     0.0        73   \n",
       "\n",
       "   visibility  pressure     id                       event_time  \\\n",
       "0           6      1015   8790 2024-10-10 20:13:27.088206+00:00   \n",
       "1           6      1020  52029 2024-10-10 20:13:27.088206+00:00   \n",
       "2           6      1036  13063 2024-10-10 20:13:27.088206+00:00   \n",
       "3           6      1024  16910 2024-10-10 20:13:27.088206+00:00   \n",
       "4           6      1021  18928 2024-10-10 20:13:27.088206+00:00   \n",
       "\n",
       "                   datetime  \n",
       "0 2019-02-14 05:00:00+00:00  \n",
       "1 2019-01-07 20:00:00+00:00  \n",
       "2 2019-02-08 06:00:00+00:00  \n",
       "3 2019-01-15 13:00:00+00:00  \n",
       "4 2019-01-07 15:00:00+00:00  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_weather = feature_group_data['city_weather']\n",
    "drivers_table = feature_group_data['drivers_table']\n",
    "routes_table = feature_group_data['routes_table']\n",
    "routes_weather = feature_group_data['routes_weather']\n",
    "traffic_table = feature_group_data['traffic_table'] \n",
    "truck_schedule_table = feature_group_data['truck_schedule_table']\n",
    "trucks_table = feature_group_data['trucks_table']\n",
    "\n",
    "\n",
    "city_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>date</th>\n",
       "      <th>temp</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>description</th>\n",
       "      <th>precip</th>\n",
       "      <th>humidity</th>\n",
       "      <th>visibility</th>\n",
       "      <th>pressure</th>\n",
       "      <th>id</th>\n",
       "      <th>event_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R-566db3fc</td>\n",
       "      <td>2019-01-21 12:00:00+00:00</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>Moderate or heavy snow showers</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "      <td>1015</td>\n",
       "      <td>245303</td>\n",
       "      <td>2024-10-10 20:13:27.063199+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R-05a6b7e1</td>\n",
       "      <td>2019-02-13 18:00:00+00:00</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63</td>\n",
       "      <td>6</td>\n",
       "      <td>1021</td>\n",
       "      <td>397270</td>\n",
       "      <td>2024-10-10 20:13:27.063199+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R-79047854</td>\n",
       "      <td>2019-01-31 00:00:00+00:00</td>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "      <td>6</td>\n",
       "      <td>1022</td>\n",
       "      <td>98159</td>\n",
       "      <td>2024-10-10 20:13:27.063199+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R-e0263659</td>\n",
       "      <td>2019-01-22 00:00:00+00:00</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66</td>\n",
       "      <td>6</td>\n",
       "      <td>1016</td>\n",
       "      <td>30437</td>\n",
       "      <td>2024-10-10 20:13:27.063199+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R-dcbddbb7</td>\n",
       "      <td>2019-02-01 12:00:00+00:00</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89</td>\n",
       "      <td>6</td>\n",
       "      <td>1011</td>\n",
       "      <td>259995</td>\n",
       "      <td>2024-10-10 20:13:27.063199+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     route_id                      date  temp  wind_speed  \\\n",
       "0  R-566db3fc 2019-01-21 12:00:00+00:00    28          16   \n",
       "1  R-05a6b7e1 2019-02-13 18:00:00+00:00    16           4   \n",
       "2  R-79047854 2019-01-31 00:00:00+00:00    55           7   \n",
       "3  R-e0263659 2019-01-22 00:00:00+00:00    75           4   \n",
       "4  R-dcbddbb7 2019-02-01 12:00:00+00:00    61           3   \n",
       "\n",
       "                      description  precip  humidity  visibility  pressure  \\\n",
       "0  Moderate or heavy snow showers     0.0        73           4      1015   \n",
       "1                           Clear     0.0        63           6      1021   \n",
       "2                           Sunny     0.0        57           6      1022   \n",
       "3                          Cloudy     0.0        66           6      1016   \n",
       "4                           Clear     0.0        89           6      1011   \n",
       "\n",
       "       id                       event_time  \n",
       "0  245303 2024-10-10 20:13:27.063199+00:00  \n",
       "1  397270 2024-10-10 20:13:27.063199+00:00  \n",
       "2   98159 2024-10-10 20:13:27.063199+00:00  \n",
       "3   30437 2024-10-10 20:13:27.063199+00:00  \n",
       "4  259995 2024-10-10 20:13:27.063199+00:00  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available keys in feature_group_data: ['city_weather', 'drivers_table', 'routes_table', 'routes_weather', 'traffic_table', 'truck_schedule_table', 'trucks_table']\n",
      "Assigned city_weather to assigned_dataframes.\n",
      "Assigned routes_weather to assigned_dataframes.\n",
      "Assigned traffic_table to assigned_dataframes.\n",
      "Assigned truck_schedule_table to assigned_dataframes.\n",
      "Assigned trucks_table to assigned_dataframes.\n",
      "   truck_id    route_id            departure_date         estimated_arrival  \\\n",
      "0  23244180  R-b1e8e9c8 2019-02-06 07:00:00+00:00 2019-02-07 04:09:00+00:00   \n",
      "1  10234289  R-d053f5bc 2019-01-22 07:00:00+00:00 2019-01-22 22:51:00+00:00   \n",
      "2  26739096  R-bf6ee666 2019-01-07 07:00:00+00:00 2019-01-07 15:54:36+00:00   \n",
      "3  20067958  R-abc9e78b 2019-01-04 07:00:00+00:00 2019-01-05 05:28:12+00:00   \n",
      "4  23639934  R-7dac228a 2019-01-31 07:00:00+00:00 2019-01-31 13:40:12+00:00   \n",
      "\n",
      "   delay    id                       event_time  \n",
      "0      1  7633 2024-10-10 20:13:27.142196+00:00  \n",
      "1      0  4651 2024-10-10 20:13:27.142196+00:00  \n",
      "2      1  1303 2024-10-10 20:13:27.142196+00:00  \n",
      "3      0   916 2024-10-10 20:13:27.142196+00:00  \n",
      "4      0  6671 2024-10-10 20:13:27.142196+00:00  \n"
     ]
    }
   ],
   "source": [
    "def assign_feature_group_data(feature_group_data, table_names):\n",
    "    # Print available keys in feature_group_data for debugging\n",
    "    print(\"Available keys in feature_group_data:\", list(feature_group_data.keys()))\n",
    "    \n",
    "    # Dictionary to store dynamically assigned DataFrames\n",
    "    assigned_dataframes = {}\n",
    "\n",
    "    # Dynamically assign the DataFrame from feature_group_data to the dictionary\n",
    "    for table_name in table_names:\n",
    "        if table_name in feature_group_data:\n",
    "            assigned_dataframes[table_name] = feature_group_data[table_name]\n",
    "            print(f\"Assigned {table_name} to assigned_dataframes.\")\n",
    "        else:\n",
    "            print(f\"KeyError: '{table_name}' not found in feature_group_data.\")\n",
    "    \n",
    "    return assigned_dataframes\n",
    "\n",
    "# List of table names matching the keys exactly as they appear in 'feature_group_data'\n",
    "table_names = ['city_weather', 'routes_weather', 'traffic_table', 'truck_schedule_table', 'trucks_table']\n",
    "\n",
    "# Call the function to assign feature group data to variables\n",
    "assigned_dataframes = assign_feature_group_data(feature_group_data, table_names)\n",
    "\n",
    "# Now you can access the DataFrames from the dictionary\n",
    "print(assigned_dataframes['truck_schedule_table'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns ['id', 'event_time'] from city_weather.\n",
      "Dropped columns ['id', 'event_time'] from drivers_table.\n",
      "Dropped columns ['id', 'event_time'] from routes_table.\n",
      "Dropped columns ['id', 'event_time'] from routes_weather.\n",
      "Dropped columns ['id', 'event_time'] from traffic_table.\n",
      "Dropped columns ['id', 'event_time'] from truck_schedule_table.\n",
      "Dropped columns ['id', 'event_time'] from trucks_table.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dfs = {\n",
    "    'city_weather': city_weather,\n",
    "    'drivers_table': drivers_table,\n",
    "    'routes_table': routes_table,\n",
    "    'routes_weather': routes_weather,\n",
    "    'traffic_table': traffic_table,\n",
    "    'truck_schedule_table': truck_schedule_table,\n",
    "    'trucks_table': trucks_table\n",
    "}\n",
    "\n",
    "\n",
    "def drop_columns_from_tables(dfs, columns_to_drop):\n",
    "    \"\"\"\n",
    "    Drops specified columns from all DataFrames in the provided dictionary.\n",
    "    \n",
    "    Parameters:\n",
    "    - dfs (dict): A dictionary where the keys are DataFrame names and the values are pandas DataFrames.\n",
    "    - columns_to_drop (list): A list of column names to be dropped from each DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: A dictionary of DataFrames with the specified columns removed.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Loop through each DataFrame in the dictionary\n",
    "    for table_name, df in dfs.items():\n",
    "        # Check if the columns exist in the DataFrame before dropping\n",
    "        cols_to_drop = [col for col in columns_to_drop if col in df.columns]\n",
    "        \n",
    "        # If there are columns to drop, drop them\n",
    "        if cols_to_drop:\n",
    "            dfs[table_name] = df.drop(columns=cols_to_drop, inplace=True)\n",
    "            print(f\"Dropped columns {cols_to_drop} from {table_name}.\")\n",
    "        else:\n",
    "            print(f\"No matching columns to drop in {table_name}.\")\n",
    "    \n",
    "    return dfs\n",
    "\n",
    "# Example usage:\n",
    "columns_to_drop = ['id', 'event_time']  # Example columns that might be present in multiple tables\n",
    "feature_group_data_cleaned = drop_columns_from_tables(feature_group_data, columns_to_drop)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 707 duplicate rows from city_weather based on columns: ['city_id', 'datetime']\n",
      "Dropped 0 duplicate rows from drivers_table based on columns: ['driver_id']\n",
      "Dropped 0 duplicate rows from routes_table based on columns: ['route_id', 'destination_id', 'origin_id']\n",
      "Dropped 0 duplicate rows from routes_weather based on columns: ['route_id', 'date']\n",
      "No duplicate check columns provided for traffic_table\n",
      "Dropped 0 duplicate rows from truck_schedule_table based on columns: ['truck_id', 'route_id', 'departure_date']\n",
      "Dropped 0 duplicate rows from trucks_table based on columns: ['truck_id']\n",
      "\n",
      "city_weather DataFrame after dropping duplicates:\n",
      "          city_id  temp  wind_speed           description  precip  humidity  \\\n",
      "0      C-731988ba    52           1  Patchy rain possible     0.0        80   \n",
      "1      C-841ebdcb    66           6         Partly cloudy     0.0        84   \n",
      "2      C-ef47bdcd    10           6                 Sunny     0.0        57   \n",
      "3      C-ff8c0c3c    34           8              Overcast     0.0       100   \n",
      "4      C-3dbd8b2e    41          11         Partly cloudy     0.0        73   \n",
      "...           ...   ...         ...                   ...     ...       ...   \n",
      "38930  C-4fe0fa24    41          11         Partly cloudy     0.0        70   \n",
      "38931  C-56b68559    25          13              Overcast     0.0        79   \n",
      "38932  C-2c9e75ef    36          10                 Clear     0.0        59   \n",
      "38933  C-03bb3e48    -9           8                Cloudy     0.0        88   \n",
      "38934  C-6ea51d66    28           6         Partly cloudy     0.0        44   \n",
      "\n",
      "       visibility  pressure                  datetime  \n",
      "0               6      1015 2019-02-14 05:00:00+00:00  \n",
      "1               6      1020 2019-01-07 20:00:00+00:00  \n",
      "2               6      1036 2019-02-08 06:00:00+00:00  \n",
      "3               6      1024 2019-01-15 13:00:00+00:00  \n",
      "4               6      1021 2019-01-07 15:00:00+00:00  \n",
      "...           ...       ...                       ...  \n",
      "38930           6      1022 2019-02-02 20:00:00+00:00  \n",
      "38931           6      1011 2019-02-04 14:00:00+00:00  \n",
      "38932           6      1023 2019-01-20 19:00:00+00:00  \n",
      "38933           6      1039 2019-01-01 09:00:00+00:00  \n",
      "38934           6      1020 2019-01-15 05:00:00+00:00  \n",
      "\n",
      "[38228 rows x 9 columns]\n",
      "\n",
      "drivers_table DataFrame after dropping duplicates:\n",
      "       driver_id               name  gender  age  experience driving_style  \\\n",
      "0     7fd8f066-0        John Graham    male   37           3  conservative   \n",
      "1     dfb33269-1    William Hoffman    male   52          28  conservative   \n",
      "2     6a2bd8a7-6          Molly Lee  female   50          17     proactive   \n",
      "3     ddcaf636-8  Christopher Rubio    male   57           9     proactive   \n",
      "4     0fa8f219-7          John Wade    male   42           9     proactive   \n",
      "...          ...                ...     ...  ...         ...           ...   \n",
      "1095  fe5449bd-f      Kevin Mueller    male   43           5  conservative   \n",
      "1096  c7d67abf-d        Pedro Floyd    male   54          19  conservative   \n",
      "1097  80368179-4     Anthony Waters    male   50          15  conservative   \n",
      "1098  69111ff9-8     Joshua Kennedy    male   51          12     proactive   \n",
      "1099  7ea1c2ea-1      Jason Schmidt    male   54          27     proactive   \n",
      "\n",
      "      ratings  vehicle_no  average_speed_mph  \n",
      "0           8    33677790              49.30  \n",
      "1           7    20516509              37.67  \n",
      "2           6    12141617              61.89  \n",
      "3           8    31057269              59.95  \n",
      "4           4    17787739              59.60  \n",
      "...       ...         ...                ...  \n",
      "1095        3    20898520              39.21  \n",
      "1096        9    18604747              38.97  \n",
      "1097        6    12725734              48.41  \n",
      "1098        4    16654459              57.94  \n",
      "1099        9    11845291              61.81  \n",
      "\n",
      "[1100 rows x 9 columns]\n",
      "\n",
      "routes_table DataFrame after dropping duplicates:\n",
      "        route_id   origin_id destination_id  distance  average_hours\n",
      "0     R-02124ef5  C-c4565ee8     C-3dbd8b2e   2018.08          40.36\n",
      "1     R-7ee42348  C-ff8c0c3c     C-927ceb5e    239.93           4.80\n",
      "2     R-038f3a7c  C-b6e04c88     C-ef47bdcd    776.33          15.53\n",
      "3     R-f39a3b9b  C-639c5e36     C-2aaf0e1a   1750.04          35.00\n",
      "4     R-22c767b0  C-3dbd8b2e     C-a9f2c329   1609.60          32.19\n",
      "...          ...         ...            ...       ...            ...\n",
      "1891  R-012c2705  C-841ebdcb     C-e5bfb4e5   1071.47          21.43\n",
      "1892  R-8d7a7fb2  C-927ceb5e     C-451776b7   1543.01          30.86\n",
      "1893  R-b20a6a61  C-594514f8     C-19236709    268.97           5.38\n",
      "1894  R-c1a857fc  C-56e39a5e     C-328bd8d3   1758.52          35.17\n",
      "1895  R-554ecdcc  C-b25a09de     C-e6dcda92    893.02          17.86\n",
      "\n",
      "[1896 rows x 5 columns]\n",
      "\n",
      "routes_weather DataFrame after dropping duplicates:\n",
      "          route_id                      date  temp  wind_speed  \\\n",
      "0       R-566db3fc 2019-01-21 12:00:00+00:00    28          16   \n",
      "1       R-05a6b7e1 2019-02-13 18:00:00+00:00    16           4   \n",
      "2       R-79047854 2019-01-31 00:00:00+00:00    55           7   \n",
      "3       R-e0263659 2019-01-22 00:00:00+00:00    75           4   \n",
      "4       R-dcbddbb7 2019-02-01 12:00:00+00:00    61           3   \n",
      "...            ...                       ...   ...         ...   \n",
      "396144  R-44d50f86 2019-02-05 06:00:00+00:00    68           9   \n",
      "396145  R-5f7528cd 2019-01-23 06:00:00+00:00    54           5   \n",
      "396146  R-fb67ca8a 2019-02-01 06:00:00+00:00    37          14   \n",
      "396147  R-57415f04 2019-01-01 06:00:00+00:00    68          10   \n",
      "396148  R-d3839035 2019-01-08 18:00:00+00:00    66           3   \n",
      "\n",
      "                           description  precip  humidity  visibility  pressure  \n",
      "0       Moderate or heavy snow showers     0.0        73           4      1015  \n",
      "1                                Clear     0.0        63           6      1021  \n",
      "2                                Sunny     0.0        57           6      1022  \n",
      "3                               Cloudy     0.0        66           6      1016  \n",
      "4                                Clear     0.0        89           6      1011  \n",
      "...                                ...     ...       ...         ...       ...  \n",
      "396144                   Partly cloudy     0.0        76           6      1018  \n",
      "396145                           Clear     0.0        32           6      1015  \n",
      "396146                   Partly cloudy     0.0        63           6      1017  \n",
      "396147                   Partly cloudy     0.0        71           6      1016  \n",
      "396148                   Partly cloudy     0.0        88           6      1023  \n",
      "\n",
      "[396149 rows x 9 columns]\n",
      "\n",
      "traffic_table DataFrame after dropping duplicates:\n",
      "           route_id  no_of_vehicles  accident                  datetime\n",
      "0        R-0f705429          2343.0         0 2019-02-06 20:00:00+00:00\n",
      "1        R-f8a25f87           552.0         0 2019-01-20 19:00:00+00:00\n",
      "2        R-3b99b000           645.0         0 2019-01-31 04:00:00+00:00\n",
      "3        R-ac453ce8           621.0         0 2019-01-12 00:00:00+00:00\n",
      "4        R-af1d28da          2916.0         0 2019-01-06 10:00:00+00:00\n",
      "...             ...             ...       ...                       ...\n",
      "2597908  R-52e3a448           531.0         0 2019-01-15 02:00:00+00:00\n",
      "2597909  R-a9ddb09f          2505.0         0 2019-01-19 10:00:00+00:00\n",
      "2597910  R-933965b8          2379.0         1 2019-02-13 18:00:00+00:00\n",
      "2597911  R-cda66d11           517.0         0 2019-01-16 04:00:00+00:00\n",
      "2597912  R-a61d7a13          2134.0         0 2019-01-15 21:00:00+00:00\n",
      "\n",
      "[2597913 rows x 4 columns]\n",
      "\n",
      "truck_schedule_table DataFrame after dropping duplicates:\n",
      "       truck_id    route_id            departure_date  \\\n",
      "0      23244180  R-b1e8e9c8 2019-02-06 07:00:00+00:00   \n",
      "1      10234289  R-d053f5bc 2019-01-22 07:00:00+00:00   \n",
      "2      26739096  R-bf6ee666 2019-01-07 07:00:00+00:00   \n",
      "3      20067958  R-abc9e78b 2019-01-04 07:00:00+00:00   \n",
      "4      23639934  R-7dac228a 2019-01-31 07:00:00+00:00   \n",
      "...         ...         ...                       ...   \n",
      "10287  30423832  R-f8b24663 2019-01-28 07:00:00+00:00   \n",
      "10288  25117738  R-c172e39f 2019-01-01 07:00:00+00:00   \n",
      "10289  11972697  R-b5a32b38 2019-01-19 07:00:00+00:00   \n",
      "10290  48204624  R-f5d9a32d 2019-01-15 07:00:00+00:00   \n",
      "10291  10787409  R-ef208446 2019-01-13 07:00:00+00:00   \n",
      "\n",
      "              estimated_arrival  delay  \n",
      "0     2019-02-07 04:09:00+00:00      1  \n",
      "1     2019-01-22 22:51:00+00:00      0  \n",
      "2     2019-01-07 15:54:36+00:00      1  \n",
      "3     2019-01-05 05:28:12+00:00      0  \n",
      "4     2019-01-31 13:40:12+00:00      0  \n",
      "...                         ...    ...  \n",
      "10287 2019-01-28 23:47:24+00:00      1  \n",
      "10288 2019-01-02 13:15:00+00:00      0  \n",
      "10289 2019-01-19 19:37:12+00:00      0  \n",
      "10290 2019-01-22 03:44:24+00:00      0  \n",
      "10291 2019-01-13 20:54:00+00:00      0  \n",
      "\n",
      "[10292 rows x 5 columns]\n",
      "\n",
      "trucks_table DataFrame after dropping duplicates:\n",
      "      truck_id  truck_age  load_capacity_pounds  mileage_mpg fuel_type\n",
      "0     19336784         11                3000.0           26    diesel\n",
      "1     35580954         10                6000.0           16    diesel\n",
      "2     19945346          9               15000.0           23    diesel\n",
      "3     31219400          8               15000.0           22    diesel\n",
      "4     18950712          7               15000.0           22       gas\n",
      "...        ...        ...                   ...          ...       ...\n",
      "1095  20409026          8                4000.0           22    diesel\n",
      "1096  12063845          9               20000.0           18       gas\n",
      "1097  29178779         10               15000.0           29    diesel\n",
      "1098  29206938          9               20000.0           18       gas\n",
      "1099  29135433         10                6000.0           23    diesel\n",
      "\n",
      "[1100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "def drop_duplicates_from_dfs(dfs, columns_to_check):   \n",
    "    for df_name, df in dfs.items():\n",
    "        if df_name in columns_to_check:\n",
    "            subset_columns = columns_to_check[df_name]\n",
    "            \n",
    "            # Check if all subset columns exist in the DataFrame\n",
    "            missing_columns = [col for col in subset_columns if col not in df.columns]\n",
    "            if missing_columns:\n",
    "                print(f\"Skipping {df_name}: Missing columns {missing_columns}\")\n",
    "                continue\n",
    "\n",
    "            before_dropping = df.shape[0]  # Count the number of rows before dropping duplicates\n",
    "            df.drop_duplicates(subset=subset_columns, inplace=True)\n",
    "            after_dropping = df.shape[0]  # Count the number of rows after dropping duplicates\n",
    "            print(f\"Dropped {before_dropping - after_dropping} duplicate rows from {df_name} based on columns: {subset_columns}\")\n",
    "        else:\n",
    "            print(f\"No duplicate check columns provided for {df_name}\")\n",
    "\n",
    "# Dictionary where the key is the DataFrame name, and the value is the subset of columns to check for duplicates\n",
    "columns_to_check = {\n",
    "    'city_weather': ['city_id', 'datetime'],\n",
    "    'routes_weather': ['route_id', 'date'],\n",
    "    'trucks_table': ['truck_id'],\n",
    "    'drivers_table': ['driver_id'],\n",
    "    'routes_table': ['route_id', 'destination_id', 'origin_id'],\n",
    "    'truck_schedule_table': ['truck_id', 'route_id', 'departure_date']\n",
    "}\n",
    "\n",
    "# Call the function to drop duplicates from the DataFrames\n",
    "drop_duplicates_from_dfs(dfs, columns_to_check)\n",
    "\n",
    "# Check the result by printing the modified DataFrames\n",
    "for df_name, df in dfs.items():\n",
    "    print(f\"\\n{df_name} DataFrame after dropping duplicates:\")\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 duplicate rows from city_weather based on columns: ['city_id', 'datetime']\n",
      "city_weather DataFrame after dropping duplicates: 38228 rows, 9 columns\n",
      "Dropped 0 duplicate rows from drivers_table based on columns: ['driver_id']\n",
      "drivers_table DataFrame after dropping duplicates: 1100 rows, 9 columns\n",
      "Dropped 0 duplicate rows from routes_table based on columns: ['route_id', 'destination_id', 'origin_id']\n",
      "routes_table DataFrame after dropping duplicates: 1896 rows, 5 columns\n",
      "Dropped 0 duplicate rows from routes_weather based on columns: ['route_id', 'date']\n",
      "routes_weather DataFrame after dropping duplicates: 396149 rows, 9 columns\n",
      "No duplicate check columns provided for traffic_table\n",
      "Dropped 0 duplicate rows from truck_schedule_table based on columns: ['truck_id', 'route_id', 'departure_date']\n",
      "truck_schedule_table DataFrame after dropping duplicates: 10292 rows, 5 columns\n",
      "Dropped 0 duplicate rows from trucks_table based on columns: ['truck_id']\n",
      "trucks_table DataFrame after dropping duplicates: 1100 rows, 5 columns\n",
      "\n",
      "city_weather DataFrame has 38228 rows and 9 columns after dropping duplicates.\n",
      "\n",
      "drivers_table DataFrame has 1100 rows and 9 columns after dropping duplicates.\n",
      "\n",
      "routes_table DataFrame has 1896 rows and 5 columns after dropping duplicates.\n",
      "\n",
      "routes_weather DataFrame has 396149 rows and 9 columns after dropping duplicates.\n",
      "\n",
      "traffic_table DataFrame has 2597913 rows and 4 columns after dropping duplicates.\n",
      "\n",
      "truck_schedule_table DataFrame has 10292 rows and 5 columns after dropping duplicates.\n",
      "\n",
      "trucks_table DataFrame has 1100 rows and 5 columns after dropping duplicates.\n"
     ]
    }
   ],
   "source": [
    "def drop_duplicates_from_dfs(dfs, columns_to_check):   \n",
    "    for df_name, df in dfs.items():\n",
    "        if df_name in columns_to_check:\n",
    "            subset_columns = columns_to_check[df_name]\n",
    "            \n",
    "            # Check if all subset columns exist in the DataFrame\n",
    "            missing_columns = [col for col in subset_columns if col not in df.columns]\n",
    "            if missing_columns:\n",
    "                print(f\"Skipping {df_name}: Missing columns {missing_columns}\")\n",
    "                continue\n",
    "\n",
    "            before_dropping = df.shape[0]  # Count the number of rows before dropping duplicates\n",
    "            df.drop_duplicates(subset=subset_columns, inplace=True)\n",
    "            after_dropping = df.shape[0]  # Count the number of rows after dropping duplicates\n",
    "            print(f\"Dropped {before_dropping - after_dropping} duplicate rows from {df_name} based on columns: {subset_columns}\")\n",
    "            \n",
    "            # Print the number of rows and columns in each DataFrame after dropping duplicates\n",
    "            print(f\"{df_name} DataFrame after dropping duplicates: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "        else:\n",
    "            print(f\"No duplicate check columns provided for {df_name}\")\n",
    "\n",
    "# Dictionary where the key is the DataFrame name, and the value is the subset of columns to check for duplicates\n",
    "columns_to_check = {\n",
    "    'city_weather': ['city_id', 'datetime'],\n",
    "    'routes_weather': ['route_id', 'date'],\n",
    "    'trucks_table': ['truck_id'],\n",
    "    'drivers_table': ['driver_id'],\n",
    "    'routes_table': ['route_id', 'destination_id', 'origin_id'],\n",
    "    'truck_schedule_table': ['truck_id', 'route_id', 'departure_date']\n",
    "}\n",
    "\n",
    "# Call the function to drop duplicates from the DataFrames\n",
    "drop_duplicates_from_dfs(dfs, columns_to_check)\n",
    "\n",
    "# Check the result by printing the modified DataFrames' shapes\n",
    "for df_name, df in dfs.items():\n",
    "    print(f\"\\n{df_name} DataFrame has {df.shape[0]} rows and {df.shape[1]} columns after dropping duplicates.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE ENGINEERING\n",
    "\n",
    "Merge Route_weather with Schedule data * create new data frame from scheduledf and add estimated_arrival and departure_date columns estimated_arriaval= df[estimated_arrival].dt.ceil(\"6H') departure_date= df[departure_date].dt.floor(\"6H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10292 entries, 0 to 10291\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype              \n",
      "---  ------             --------------  -----              \n",
      " 0   truck_id           10292 non-null  int64              \n",
      " 1   route_id           10292 non-null  object             \n",
      " 2   departure_date     10292 non-null  datetime64[us, UTC]\n",
      " 3   estimated_arrival  10292 non-null  datetime64[us, UTC]\n",
      " 4   delay              10292 non-null  int64              \n",
      "dtypes: datetime64[us, UTC](2), int64(2), object(1)\n",
      "memory usage: 402.2+ KB\n"
     ]
    }
   ],
   "source": [
    "truck_schedule_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 396149 entries, 0 to 396148\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count   Dtype              \n",
      "---  ------       --------------   -----              \n",
      " 0   route_id     396149 non-null  object             \n",
      " 1   date         396149 non-null  datetime64[us, UTC]\n",
      " 2   temp         396149 non-null  int64              \n",
      " 3   wind_speed   396149 non-null  int64              \n",
      " 4   description  396149 non-null  object             \n",
      " 5   precip       396149 non-null  float64            \n",
      " 6   humidity     396149 non-null  int64              \n",
      " 7   visibility   396149 non-null  int64              \n",
      " 8   pressure     396149 non-null  int64              \n",
      "dtypes: datetime64[us, UTC](1), float64(1), int64(5), object(2)\n",
      "memory usage: 27.2+ MB\n"
     ]
    }
   ],
   "source": [
    "routes_weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed truck_schedule_table with route weather data merge:\n",
      "    truck_id    route_id            departure_date         estimated_arrival  \\\n",
      "0  23244180  R-b1e8e9c8 2019-02-06 06:00:00+00:00 2019-02-07 06:00:00+00:00   \n",
      "1  23244180  R-b1e8e9c8 2019-02-06 06:00:00+00:00 2019-02-07 06:00:00+00:00   \n",
      "2  23244180  R-b1e8e9c8 2019-02-06 06:00:00+00:00 2019-02-07 06:00:00+00:00   \n",
      "3  23244180  R-b1e8e9c8 2019-02-06 06:00:00+00:00 2019-02-07 06:00:00+00:00   \n",
      "4  23244180  R-b1e8e9c8 2019-02-06 06:00:00+00:00 2019-02-07 06:00:00+00:00   \n",
      "\n",
      "   delay                      date  temp  wind_speed        description  \\\n",
      "0      1 2019-02-06 06:00:00+00:00  52.0         7.0              Clear   \n",
      "1      1 2019-02-06 12:00:00+00:00  37.0         4.0  Patchy light rain   \n",
      "2      1 2019-02-06 18:00:00+00:00  36.0         4.0  Patchy light rain   \n",
      "3      1 2019-02-07 00:00:00+00:00  52.0         7.0              Clear   \n",
      "4      1 2019-02-07 06:00:00+00:00  52.0         7.0              Clear   \n",
      "\n",
      "   precip  humidity  visibility  pressure  \n",
      "0     0.0      86.0         6.0    1020.0  \n",
      "1     0.0      99.0         6.0    1010.0  \n",
      "2     0.0      98.0         6.0    1010.0  \n",
      "3     0.0      85.0         6.0    1021.0  \n",
      "4     0.0      85.0         6.0    1021.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_dates(df, estimated_arrival_column, departure_date_column):\n",
    "    # Function to convert to UTC if not already timezone-aware\n",
    "    def convert_to_utc(series):\n",
    "        if series.dt.tz is None:  # Check if the series is not timezone-aware\n",
    "            return series.dt.tz_localize('UTC')\n",
    "        else:\n",
    "            return series.dt.tz_convert('UTC')  # Convert to UTC if it already has a timezone\n",
    "\n",
    "    # Step 1: Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Step 2: Convert both columns to datetime format and set to UTC timezone\n",
    "    df_copy[estimated_arrival_column] = convert_to_utc(pd.to_datetime(df_copy[estimated_arrival_column], errors='coerce'))\n",
    "    df_copy[departure_date_column] = convert_to_utc(pd.to_datetime(df_copy[departure_date_column], errors='coerce'))\n",
    "\n",
    "    # Step 3: Apply ceil operation to estimated arrival\n",
    "    df_copy[estimated_arrival_column] = df_copy[estimated_arrival_column].dt.ceil(\"6H\")\n",
    "\n",
    "    # Step 4: Floor the 'departure_date' column to the nearest 6 hours\n",
    "    df_copy[departure_date_column] = df_copy[departure_date_column].dt.floor(\"6H\")\n",
    "\n",
    "    # Step 5: Create a new column 'date' with date ranges between 'departure_date' and 'estimated_arrival'\n",
    "    df_copy['date'] = [\n",
    "        pd.date_range(start=row[departure_date_column], end=row[estimated_arrival_column], freq='6H')\n",
    "        for index, row in df_copy.iterrows()\n",
    "    ]\n",
    "    \n",
    "    # Step 6: Explode the 'date' column to separate rows for each date in the range\n",
    "    df_copy = df_copy.explode('date').reset_index(drop=True)\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "# Define target table(s) to process\n",
    "target_tables = ['truck_schedule_table']  # Your actual table names from the 'dfs' dictionary\n",
    "departure_date_column = 'departure_date'\n",
    "estimated_arrival_column = 'estimated_arrival'\n",
    "\n",
    "# Process the DataFrames\n",
    "for table_name in list(dfs.keys()):  # Use list(dfs.keys()) to avoid changing the dictionary during iteration\n",
    "    df = dfs[table_name]\n",
    "    if table_name in target_tables:\n",
    "        # Create a copy and process dates\n",
    "        result_df_copy = process_dates(df, estimated_arrival_column, departure_date_column)\n",
    "        \n",
    "        # Merge with routes_weather on 'route_id' and 'date'\n",
    "        scheduled_weather = pd.merge(result_df_copy, dfs['routes_weather'], on=['route_id', 'date'], how='left')\n",
    "\n",
    "        # Display or log the merged DataFrame for review\n",
    "        print(f\"Processed {table_name} with route weather data merge:\\n\", scheduled_weather.head())\n",
    "\n",
    "        # Save the processed DataFrame under a new key in the 'dfs' dictionary\n",
    "        dfs[f'{table_name}_processed'] = scheduled_weather\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the resultant dataframe with route_weather on route_id and date (left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truck_id</th>\n",
       "      <th>route_id</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>estimated_arrival</th>\n",
       "      <th>delay</th>\n",
       "      <th>date</th>\n",
       "      <th>temp</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>description</th>\n",
       "      <th>precip</th>\n",
       "      <th>humidity</th>\n",
       "      <th>visibility</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23244180</td>\n",
       "      <td>R-b1e8e9c8</td>\n",
       "      <td>2019-02-06 06:00:00+00:00</td>\n",
       "      <td>2019-02-07 06:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-02-06 06:00:00+00:00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23244180</td>\n",
       "      <td>R-b1e8e9c8</td>\n",
       "      <td>2019-02-06 06:00:00+00:00</td>\n",
       "      <td>2019-02-07 06:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-02-06 12:00:00+00:00</td>\n",
       "      <td>37.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Patchy light rain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23244180</td>\n",
       "      <td>R-b1e8e9c8</td>\n",
       "      <td>2019-02-06 06:00:00+00:00</td>\n",
       "      <td>2019-02-07 06:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-02-06 18:00:00+00:00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Patchy light rain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23244180</td>\n",
       "      <td>R-b1e8e9c8</td>\n",
       "      <td>2019-02-06 06:00:00+00:00</td>\n",
       "      <td>2019-02-07 06:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-02-07 00:00:00+00:00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23244180</td>\n",
       "      <td>R-b1e8e9c8</td>\n",
       "      <td>2019-02-06 06:00:00+00:00</td>\n",
       "      <td>2019-02-07 06:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-02-07 06:00:00+00:00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59674</th>\n",
       "      <td>48204624</td>\n",
       "      <td>R-f5d9a32d</td>\n",
       "      <td>2019-01-15 06:00:00+00:00</td>\n",
       "      <td>2019-01-22 06:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-22 06:00:00+00:00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Moderate snow</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59675</th>\n",
       "      <td>10787409</td>\n",
       "      <td>R-ef208446</td>\n",
       "      <td>2019-01-13 06:00:00+00:00</td>\n",
       "      <td>2019-01-14 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-13 06:00:00+00:00</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59676</th>\n",
       "      <td>10787409</td>\n",
       "      <td>R-ef208446</td>\n",
       "      <td>2019-01-13 06:00:00+00:00</td>\n",
       "      <td>2019-01-14 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-13 12:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59677</th>\n",
       "      <td>10787409</td>\n",
       "      <td>R-ef208446</td>\n",
       "      <td>2019-01-13 06:00:00+00:00</td>\n",
       "      <td>2019-01-14 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-13 18:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59678</th>\n",
       "      <td>10787409</td>\n",
       "      <td>R-ef208446</td>\n",
       "      <td>2019-01-13 06:00:00+00:00</td>\n",
       "      <td>2019-01-14 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-14 00:00:00+00:00</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1017.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59679 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       truck_id    route_id            departure_date  \\\n",
       "0      23244180  R-b1e8e9c8 2019-02-06 06:00:00+00:00   \n",
       "1      23244180  R-b1e8e9c8 2019-02-06 06:00:00+00:00   \n",
       "2      23244180  R-b1e8e9c8 2019-02-06 06:00:00+00:00   \n",
       "3      23244180  R-b1e8e9c8 2019-02-06 06:00:00+00:00   \n",
       "4      23244180  R-b1e8e9c8 2019-02-06 06:00:00+00:00   \n",
       "...         ...         ...                       ...   \n",
       "59674  48204624  R-f5d9a32d 2019-01-15 06:00:00+00:00   \n",
       "59675  10787409  R-ef208446 2019-01-13 06:00:00+00:00   \n",
       "59676  10787409  R-ef208446 2019-01-13 06:00:00+00:00   \n",
       "59677  10787409  R-ef208446 2019-01-13 06:00:00+00:00   \n",
       "59678  10787409  R-ef208446 2019-01-13 06:00:00+00:00   \n",
       "\n",
       "              estimated_arrival  delay                      date  temp  \\\n",
       "0     2019-02-07 06:00:00+00:00      1 2019-02-06 06:00:00+00:00  52.0   \n",
       "1     2019-02-07 06:00:00+00:00      1 2019-02-06 12:00:00+00:00  37.0   \n",
       "2     2019-02-07 06:00:00+00:00      1 2019-02-06 18:00:00+00:00  36.0   \n",
       "3     2019-02-07 06:00:00+00:00      1 2019-02-07 00:00:00+00:00  52.0   \n",
       "4     2019-02-07 06:00:00+00:00      1 2019-02-07 06:00:00+00:00  52.0   \n",
       "...                         ...    ...                       ...   ...   \n",
       "59674 2019-01-22 06:00:00+00:00      0 2019-01-22 06:00:00+00:00  30.0   \n",
       "59675 2019-01-14 00:00:00+00:00      0 2019-01-13 06:00:00+00:00  68.0   \n",
       "59676 2019-01-14 00:00:00+00:00      0 2019-01-13 12:00:00+00:00   NaN   \n",
       "59677 2019-01-14 00:00:00+00:00      0 2019-01-13 18:00:00+00:00   NaN   \n",
       "59678 2019-01-14 00:00:00+00:00      0 2019-01-14 00:00:00+00:00  66.0   \n",
       "\n",
       "       wind_speed        description  precip  humidity  visibility  pressure  \n",
       "0             7.0              Clear     0.0      86.0         6.0    1020.0  \n",
       "1             4.0  Patchy light rain     0.0      99.0         6.0    1010.0  \n",
       "2             4.0  Patchy light rain     0.0      98.0         6.0    1010.0  \n",
       "3             7.0              Clear     0.0      85.0         6.0    1021.0  \n",
       "4             7.0              Clear     0.0      85.0         6.0    1021.0  \n",
       "...           ...                ...     ...       ...         ...       ...  \n",
       "59674        14.0      Moderate snow     0.0      83.0         3.0    1011.0  \n",
       "59675         1.0              Clear     0.0      82.0         6.0    1017.0  \n",
       "59676         NaN                NaN     NaN       NaN         NaN       NaN  \n",
       "59677         NaN                NaN     NaN       NaN         NaN       NaN  \n",
       "59678         2.0              Clear     0.0      84.0         6.0    1017.0  \n",
       "\n",
       "[59679 rows x 13 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduled_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
