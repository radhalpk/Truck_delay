{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1044630\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.75s) \n",
      "Downloaded feature group: final_df_feature_group (version 1)\n",
      "   unique_id  truck_id    route_id            departure_date  \\\n",
      "0       2172  31794890  R-d1a6a43c 2019-01-16 06:00:00+00:00   \n",
      "1       5331  54036321  R-11ea3024 2019-01-01 06:00:00+00:00   \n",
      "2       3135  32048264  R-6cb722d8 2019-01-21 06:00:00+00:00   \n",
      "3       5129  20339561  R-3d1310d5 2019-01-04 06:00:00+00:00   \n",
      "4       2938  53208128  R-ddae5148 2019-01-10 06:00:00+00:00   \n",
      "\n",
      "          estimated_arrival  route_avg_temp  route_avg_wind_speed  \\\n",
      "0 2019-01-17 06:00:00+00:00       62.800000              9.600000   \n",
      "1 2019-01-02 18:00:00+00:00       49.166667             10.166667   \n",
      "2 2019-01-22 18:00:00+00:00       61.142857              4.571429   \n",
      "3 2019-01-05 00:00:00+00:00       69.500000             12.250000   \n",
      "4 2019-01-10 18:00:00+00:00       72.333333             13.000000   \n",
      "\n",
      "   route_avg_precip  route_avg_humidity  route_avg_visibility  ...  \\\n",
      "0          0.000000           78.800000              6.000000  ...   \n",
      "1          0.083333           77.500000              4.333333  ...   \n",
      "2          0.000000           60.285714              6.000000  ...   \n",
      "3          0.000000           73.250000              6.000000  ...   \n",
      "4          0.000000           75.666667              5.000000  ...   \n",
      "\n",
      "              name gender age experience driving_style ratings  vehicle_no  \\\n",
      "0       Lucas Shaw   male  42          9     proactive       8    31794890   \n",
      "1      Jose Taylor   male  49         10  conservative       2    54036321   \n",
      "2  Kevin Rasmussen   male  45          8     proactive       4    32048264   \n",
      "3   David Alvarado   male  49          8  conservative       7    20339561   \n",
      "4      Hunter Ruiz   male  53         14     proactive       6    53208128   \n",
      "\n",
      "   average_speed_mph  is_midnight  delay  \n",
      "0              59.95            1      0  \n",
      "1              40.13            1      0  \n",
      "2              64.31            1      1  \n",
      "3              33.94            1      0  \n",
      "4              57.85            0      0  \n",
      "\n",
      "[5 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "from hsfs.client.exceptions import RestAPIError\n",
    "\n",
    "# Establish connection to Hopsworks\n",
    "project = hopsworks.login(\n",
    "    api_key_value=\"dYTVrTVvbj6Qw82i.YGKHdS9snQYFgOADJIvLdvZ2n2S5BxIAOtvPUEmAyd56bvaG6xhhGyNM3nYbexaP\"\n",
    ")\n",
    "\n",
    "# Access the Feature Store\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "# Specify the feature group and its version\n",
    "feature_group_name = \"final_df_feature_group\"\n",
    "feature_group_version = 1\n",
    "\n",
    "try:\n",
    "    # Retrieve the 'final_df_feature_group' feature group by its name and version\n",
    "    final_df_fg = fs.get_feature_group(feature_group_name, version=feature_group_version)\n",
    "    \n",
    "    # Read the feature group as a Pandas DataFrame\n",
    "    final_df = final_df_fg.read()\n",
    "\n",
    "    # Print success message and display the first few rows of the DataFrame\n",
    "    print(f\"Downloaded feature group: {feature_group_name} (version {feature_group_version})\")\n",
    "    print(final_df.head())  # Optionally display the first few rows of the DataFrame\n",
    "\n",
    "except RestAPIError as e:\n",
    "    print(f\"Error downloading feature group: {feature_group_name} (version {feature_group_version})\")\n",
    "    print(e)\n",
    "\n",
    "# Now you have the `final_df` DataFrame containing data from 'final_df_feature_group'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10290, 49)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_id                         0\n",
       "truck_id                          0\n",
       "route_id                          0\n",
       "departure_date                    0\n",
       "estimated_arrival                 0\n",
       "route_avg_temp                    0\n",
       "route_avg_wind_speed              0\n",
       "route_avg_precip                  0\n",
       "route_avg_humidity                0\n",
       "route_avg_visibility              0\n",
       "route_avg_pressure                0\n",
       "route_description                 0\n",
       "estimated_arrival_nearest_hour    0\n",
       "departure_date_nearest_hour       0\n",
       "origin_id                         0\n",
       "destination_id                    0\n",
       "distance                          0\n",
       "average_hours                     0\n",
       "temp_origin                       0\n",
       "wind_speed_origin                 0\n",
       "description_origin                0\n",
       "precip_origin                     0\n",
       "humidity_origin                   0\n",
       "visibility_origin                 0\n",
       "pressure_origin                   0\n",
       "temp_destination                  0\n",
       "wind_speed_destination            0\n",
       "description_destination           0\n",
       "precip_destination                0\n",
       "humidity_destination              0\n",
       "visibility_destination            0\n",
       "pressure_destination              0\n",
       "avg_no_of_vehicles                0\n",
       "accident                          0\n",
       "truck_age                         0\n",
       "load_capacity_pounds              0\n",
       "mileage_mpg                       0\n",
       "fuel_type                         0\n",
       "driver_id                         0\n",
       "name                              0\n",
       "gender                            0\n",
       "age                               0\n",
       "experience                        0\n",
       "driving_style                     0\n",
       "ratings                           0\n",
       "vehicle_no                        0\n",
       "average_speed_mph                 0\n",
       "is_midnight                       0\n",
       "delay                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1044630\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.80s) \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['origin_temp', 'origin_wind_speed', 'origin_precip', 'origin_humidity', 'origin_visibility', 'origin_pressure', 'destination_temp', 'destination_wind_speed', 'destination_precip', 'destination_humidity', 'destination_visibility', 'destination_pressure'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 71\u001b[0m\n\u001b[1;32m     68\u001b[0m fs \u001b[38;5;241m=\u001b[39m project\u001b[38;5;241m.\u001b[39mget_feature_store()\n\u001b[1;32m     70\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Phase2Pipeline(fs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_df_feature_group\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 71\u001b[0m X_train, X_val, X_test, y_train, y_val, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# You can now proceed with the training, validation, and testing.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 57\u001b[0m, in \u001b[0;36mPhase2Pipeline.execute_pipeline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m final_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_final_df()\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Handle null values\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m final_df_clean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_null_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Split the data\u001b[39;00m\n\u001b[1;32m     60\u001b[0m X_train, X_val, X_test, y_train, y_val, y_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_validation_test_split(final_df_clean)\n",
      "Cell \u001b[0;32mIn[8], line 31\u001b[0m, in \u001b[0;36mPhase2Pipeline.handle_null_values\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m     28\u001b[0m target \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelay\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Fill nulls in continuous columns\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m df[cts_cols] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcts_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mfillna(df[cts_cols]\u001b[38;5;241m.\u001b[39mmedian())\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Fill nulls in categorical columns\u001b[39;00m\n\u001b[1;32m     34\u001b[0m df[cat_cols] \u001b[38;5;241m=\u001b[39m df[cat_cols]\u001b[38;5;241m.\u001b[39mfillna(df[cat_cols]\u001b[38;5;241m.\u001b[39mmode()\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/Desktop/projects/Truck_delay/myenv2/lib/python3.10/site-packages/pandas/core/frame.py:3899\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3898\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3899\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3901\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/projects/Truck_delay/myenv2/lib/python3.10/site-packages/pandas/core/indexes/base.py:6115\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6113\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6115\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6117\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6119\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/projects/Truck_delay/myenv2/lib/python3.10/site-packages/pandas/core/indexes/base.py:6179\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6178\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6179\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['origin_temp', 'origin_wind_speed', 'origin_precip', 'origin_humidity', 'origin_visibility', 'origin_pressure', 'destination_temp', 'destination_wind_speed', 'destination_precip', 'destination_humidity', 'destination_visibility', 'destination_pressure'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class Phase2Pipeline:\n",
    "    \n",
    "    cts_cols = ['route_avg_temp', 'route_avg_wind_speed', 'route_avg_precip', 'route_avg_humidity', \n",
    "                    'route_avg_visibility', 'route_avg_pressure', 'distance', 'average_hours',\n",
    "                    'temp_origin', 'wind_speed_origin', 'precip_origin', 'humidity_origin', \n",
    "                    'visibility_origin', 'pressure_origin', 'temp_destination', 'wind_speed_destination',\n",
    "                    'precip_destination', 'humidity_destination', 'visibility_destination',\n",
    "                    'pressure_destination', 'avg_no_of_vehicles', 'truck_age', 'load_capacity_pounds', \n",
    "                    'mileage_mpg', 'age', 'experience', 'average_speed_mph']\n",
    "\n",
    "    cat_cols = ['route_description', 'description_origin', 'description_destination', 'accident', \n",
    "                    'fuel_type', 'gender', 'driving_style', 'ratings', 'is_midnight']\n",
    "\n",
    "    target = ['delay']\n",
    "    \n",
    "    \n",
    "    def __init__(self, feature_store, feature_group_name):\n",
    "        self.feature_store = feature_store\n",
    "        self.feature_group_name = feature_group_name\n",
    "\n",
    "    def load_final_df(self):\n",
    "        # Load final DataFrame from feature store\n",
    "        fg = self.feature_store.get_feature_group(name=self.feature_group_name, version=1)\n",
    "        final_df = fg.read()\n",
    "        return final_df\n",
    "\n",
    "    def handle_null_values(self, df):\n",
    "        # Fill null values in continuous columns with the median\n",
    "        \n",
    "\n",
    "        # Fill nulls in continuous columns\n",
    "       df[cts_cols] = df[cts_cols].fillna(df[cts_cols].median())\n",
    "\n",
    "        # Fill nulls in categorical columns\n",
    "       df[cat_cols] = df[cat_cols].fillna(df[cat_cols].mode().iloc[0])\n",
    "\n",
    "       return df\n",
    "\n",
    "    def train_validation_test_split(self, df):\n",
    "        # Remove ID columns if any\n",
    "        df = df.drop(columns=['unique_id', 'truck_id', 'route_id'])\n",
    "\n",
    "        # Split features and target\n",
    "        X = df[cts_cols + cat_cols]\n",
    "        y = df[target]\n",
    "\n",
    "        # Split data into train, validation, and test sets\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "        return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "    def execute_pipeline(self):\n",
    "        # Load the final DataFrame\n",
    "        final_df = self.load_final_df()\n",
    "\n",
    "        # Handle null values\n",
    "        final_df_clean = self.handle_null_values(final_df)\n",
    "\n",
    "        # Split the data\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test = self.train_validation_test_split(final_df_clean)\n",
    "\n",
    "        return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "# Example usage\n",
    "project = hopsworks.login(\n",
    "    api_key_value=\"dYTVrTVvbj6Qw82i.YGKHdS9snQYFgOADJIvLdvZ2n2S5BxIAOtvPUEmAyd56bvaG6xhhGyNM3nYbexaP\"\n",
    ")\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "pipeline = Phase2Pipeline(fs, \"final_df_feature_group\")\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = pipeline.execute_pipeline()\n",
    "\n",
    "# You can now proceed with the training, validation, and testing.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
